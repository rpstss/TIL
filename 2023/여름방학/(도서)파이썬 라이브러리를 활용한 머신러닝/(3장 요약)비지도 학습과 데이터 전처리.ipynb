{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b26f8132-cfb4-4b96-9e59-1feeadeb8569",
   "metadata": {},
   "source": [
    "# **<span style=\"color:blue\">비지도 학습의 종류</span>** \n",
    "---\n",
    "- 비지도 변환: 데이터를 새롭게 변환하여 원래 데이터를 쉽게 이해할 수 있도록 하는 알고리즘\n",
    "   - 차원 축소: 특성이 많은 데이터의 특성 수를, 중요한 특징만 뽑아서 줄이는 것\n",
    "   - 데이터를 구성하는 단위나 성분을 찾기도 -> 텍스트에서 주제를 추출하기\n",
    "- 군집: 데이터를 비슷한 것끼리 묶는 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d7954d-fed6-4d5a-8ad8-7401421a3c86",
   "metadata": {},
   "source": [
    "# **<span style=\"color:blue\">비지도 학습의 도전 과제</span>** \n",
    "---\n",
    "- 알고리즘이 뭔가 유용한 것을 학습했는지 평가하는 것이 가장 어려움(보통 레이블이 없는 데이터에 적용하기 때문) -> 직접 확인하는 것이 평가의 유일한 방법일 경우가 많음\n",
    "- 따라서 데이터 사이언티스트가 데이터를 잘 이해하고 싶을 때 탐색적 분석 단계에서 많이 사용함\n",
    "- 데이터 전처리 단계에서도 많이 사용함 -> 메모리와 시간을 줄일 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff29729-0aa6-4f49-912e-2941f588c835",
   "metadata": {},
   "source": [
    "# **<span style=\"color:blue\">데이터 전처리와 스케일 조정</span>** \n",
    "---\n",
    "- 스케일 조정은 레이블을 주어주지 않으므로 비지도 방식으로 이해할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c312ae-243b-4556-9f16-53de6029f8e2",
   "metadata": {},
   "source": [
    "## **<span style=\"color:green\">여러 가지 전처리 방법</span>**\n",
    "- StandardScaler: 각 특성의 평균을 0, 분산을 1로 변경. 모든 특성들이 같은 크기를 갖게 됨. 특성의 최솟값과 최댓값 크기를 제한하지는 않음\n",
    "- RobustScaler: 특성들이 같은 크기를 갖게 됨. StandardScaler에서 평균과 분산 대신, 중간 값과 사분위 값을 사용함. 이상치의 영향을 받지 않음\n",
    "- MinMaxScaler: 모든 특성이 -과 1 사이에 위치하도록 데이터를 변경함\n",
    "- Normalize: 특성 벡터의 유클리디안 길이가 1이 되도록 데이터 포인트를 조정함. 데이터의 방향 또는 각도만이 중요할 때 사용함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c22f15-6798-4c8c-acd2-06e0c19ad203",
   "metadata": {},
   "source": [
    "## **<span style=\"color:green\">데이터 변환 적용하기</span>** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9895bcc-40d0-45de-ad4b-a4f3d49013e0",
   "metadata": {},
   "source": [
    "## **<span style=\"color:green\">Quantile Transformer와 PowerTransformer</span>**\n",
    "- Quantile Transformer: 1000개의 분위를 사용하여 데이터를 균등하게 분포시킴. 이상치에 민감하지 않으며 전체 데이터를 0과 1사이로 압축함\n",
    "- PowerTransformer: 특성별로 정규분포 형태에 가깝도록 변환해줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c71fe72-210a-4613-b801-bf2e44fb5837",
   "metadata": {},
   "source": [
    "## **<span style=\"color:green\">훈련 데이터와 테스트 데이터의 스케일을 같은 방법으로 조정하기</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2765504c-871b-4434-be2f-0ae8b85f79e7",
   "metadata": {},
   "source": [
    "## **<span style=\"color:green\">지도 학습에서 데이터 전처리 효과</span>**\n",
    "- 아래는 스케일 조정 전처리 예시임\n",
    "- 결측치를 처리하는 방법 중, 평균이나 최빈값으로 대체하는 SimpleImputer와 최근접 이웃 방식으로 대체하는 KNNImputer가 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80cb0f0-27ac-4f78-8dac-be066f5df48f",
   "metadata": {},
   "source": [
    "# **<span style=\"color:blue\">차원 축소, 특성 추출, 매니폴드 학습</span>** \n",
    "---\n",
    "- 데이터 변환 -> 시각화, 데이터를 압축, 추가적인 처리(지도 학습에 사용하기 위함)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636922e6-28dc-4c85-91d2-8de7d2faf894",
   "metadata": {},
   "source": [
    "## **<span style=\"color:green\">주성분 분석(PCA)</span>**\n",
    "- 주성분 분석: 특성들이 통계적으로 상관관계가 없도록 데이터셋을 회전시키는 기술 -> 데이터를 설명하는데 얼마나 중요하냐에 따라 새로운 특성중 일부만 선택\n",
    "- 아래에 그래프에서 성분 1인 분산이 가장 큰 방향을 찾음. 이 방향은 데이터에서 가장 많은 정보를 담고 있는 방향임(특성들의 상관관계가 가장 큰 방향)\n",
    "- 첫 번째 방향과 직각인 방향 중에서 가장 많은 정보를 담은 방향을 찾음\n",
    "- 주성분: 위의 과정을 거쳐 찾은 방향인, 데이터의 주된 분산의 방향. 일반적으로 특성 개수만큼의 주성분이 있음\n",
    "- PCA 변환: 데이터를 회전시키고 분산이 작은 주성분을 덜어내는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daaa768-5309-40eb-88c2-bce5380f5a9b",
   "metadata": {},
   "source": [
    "### **PCA를 적용해 유방암 데이터셋 시각화하기**\n",
    "- PCA는 고차원 데이터셋의 시각화에 많이 사용됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b439827d-2c47-465d-b660-2435751a8fd3",
   "metadata": {},
   "source": [
    "### **고유얼굴(eigenface) 특성 추출**\n",
    "- PCA는 특성 추출에도 이용함\n",
    "- 설명된 분산의 비율: 각 주성분이 얼만큼의 분산을 표현하는지 비교할 수 있음\n",
    "   - 가장 큰 분산의 방향을 차례대로 찾기 때문에 맨 처음 찾은 주성분의 설명된 분산의 비율이 제일 크고, 뒤로 갈수록 작아짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f235c7-53b1-491c-99ec-a6b55723f07f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **<span style=\"color:green\">비음수 행렬 분해(NMF)</span>**\n",
    "- NMF: 유용한 특성을 뽑아내기 위한 또 다른 비지도 학습 알고리즘 -> PCA와 비슷하고, 차원 축소에도 사용할 수 있음\n",
    "- PCA에서는 데이터의 분산이 가장 크고 수직인 성분을 찾았다면, NMF에서는 음수가 아닌 성분과 계수 값을 찾음 -> 음수가 아닌 특성을 가진 데이터에서만 사용\n",
    "- 여러 사람의 목소리가 담긴 오디오 트랙이나 여러 악기로 이뤄진 음악처럼, 독립된 소스를 추가하여 만들어진 데이터에 유용함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1498b582-9997-4d86-a8f8-6d225166e8d0",
   "metadata": {},
   "source": [
    "### **인위적 데이터에 NMF 적용하기**\n",
    "- 주어진 데이터가 양수인지 확인해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399846e8-3bf3-4b3f-b0a9-0fe872883ff5",
   "metadata": {},
   "source": [
    "### **얼굴 이미지에 NMF 적용하기**\n",
    "- 핵심 매개변수는 추출할 성분의 개수임\n",
    "- 변환을 되돌린 결과는 PCA 품질이 더 좋음 -> PCA는 재구성 측면에서 최선의 방향을 찾는데 반면, NMF는 데이터에 있는 유용한 패턴을 찾는데 활용함\n",
    "- PCA나 NMF처럼 데이터 포인트를 일정 개수의 성분을 사용해 가중치 합으로 분해가능한 알고리즘이 많음\n",
    "- 패턴 추출에 관심이 있다면 분해 메서드 페이지를 살펴보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ed805b-a28e-42c7-b3ab-0ac566c77f3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **<span style=\"color:green\">t-SNE를 이용한 매니폴드 학습</span>**\n",
    "- PCA는 산점도로 시각화할 수 있기 때문에 데이터 변환에 가장 먼저 시도해볼 만하지만, 유용성은 떨어짐\n",
    "- 매니폴드 학습 알고리즘: 시각화 알고리즘. 훨씬 복잡한 매핑을 만들어 더 나은 시각화를 제공함. t-SNE를 아주 많이 사용함\n",
    "- 테스트 세트에는 적용할 수 없기 때문에, 학습용의 시각화를 목적으로만 사용(특히, EDA에서 사용)\n",
    "- t-SNE: 데이터 포인트 사이의 거리를 가장 잘 보존하는 2차원 표현을 찾는 것. 각 데이터 포인트를 2차원에 무작위로 표현한 후, 원본 특성 공간에서 가까운 포인트에 집중함 -> 이웃 데이터 포인트에 대한 정보를 보존하는데 노력함\n",
    "- 매개변수를 약간 조정할 수 있지만, 기본값으로도 잘 작동하는 경우가 많음. 매개변수를 변경해도 큰 효과는 기대하기 힘듬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b12c1-5d27-4ff1-aea9-8157461e48ec",
   "metadata": {},
   "source": [
    "# **<span style=\"color:blue\">군집</span>** \n",
    "---\n",
    "- 군집: 데이터셋을 클러스터라는 그룹으로 나누는 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7670e62c-b1d7-4cf4-8c64-6b96091f5d38",
   "metadata": {},
   "source": [
    "## **<span style=\"color:green\">k-평균 군집</span>**\n",
    "- 데이터의 어떤 영역을 대표하는 클러스터 중심을 찾음\n",
    "- 두 단계를 반복함\n",
    "   1. 데이터 포인트를 가장 가까운 클러스터 중심에 할당\n",
    "   2. 클러스터에 할당된 데이터 포인트의 평균으로 클러스터 중심을 다시 지정\n",
    "- 클러스터에 할당되는 데이터 포인트에 변화가 없을 때 알고리즘 종료\n",
    "- 레이블 자체에는 의미가 없음\n",
    "- 난수 초깃값에 따라 알고리즘 출력이 달라짐\n",
    "- 클러스터의 개수를 지정해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8a3c14-8d40-4c08-b476-5cc39267ca4d",
   "metadata": {},
   "source": [
    "### **k-평균 알고리즘이 실패하는 경우**\n",
    "- 각 클러스터를 정의하는 것이 중심 하나뿐이므로 클러스터는 둥근 형태로 나타남\n",
    "- k-평균은 모든 클러스터의 반경이 똑같다고 가정함 -> 경계를 중심 사이의 중간으로 설정. 밀도가 다른 데이터에 문제가 생길 수 있음\n",
    "- 클러스터에서 모든 방향이 똑같이 중요하다고 가정함 -> 대각선으로 늘어진 데이터를 잘 처리하지 못함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f2521a-83f3-4076-b2c9-6c8287a55fc0",
   "metadata": {},
   "source": [
    "### **벡터 양자화 또는 분해 메서드로서의 k-평균**\n",
    "- 벡터 양자화: k-평균을 각 포인트가 하나의 성분으로 분해되는 관점으로 보는 것(클러스터 중심을 기준으로)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936995c4-dc33-4434-ac5f-630f2256dcdf",
   "metadata": {},
   "source": [
    "## **<span style=\"color:green\">병합 군집</span>**\n",
    "- 각 포인트를 하나의 클러스터로 지정하고, 종료 조건(클러스터 개수)을 만족할 때까지 가장 비슷한 두 클러스터를 합쳐나감\n",
    "- linkage 옵션에서 가장 비슷한 클러스터를 측정하는 방법을 지정함\n",
    "   - ward: 모든 클러스터 내의 분산을 가장 작게 증가시키는 두 클러스터를 합침 -> 비교적 크기가 비슷한 클러스터가 만들어짐\n",
    "   - average: 클러스터 포인트 사이의 평균 거리가 가장 짧은 두 클러스터를 합침\n",
    "   - complete: 클러스터 포인트 사이의 최대 거리가 가장 짧은 두 클러스터를 합침\n",
    "- 새로운 데이터 포인트에 대해서 예측을 할 수 없음\n",
    "- 복잡한 형상을 구분하지는 못함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405ab105-843a-42a1-97c4-c35c841c43bb",
   "metadata": {},
   "source": [
    "### **계층적 군집과 덴드로그램**\n",
    "- 병합 군집은 계층적 군집을 만듬\n",
    "- 덴드로그램: 계층 군집을 시각화하는 도구. 다차원 데이터셋을 처리할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1395c09-a6af-426e-bf26-620c0b3c7e60",
   "metadata": {},
   "source": [
    "## **<span style=\"color:green\">DBSCAN</span>**\n",
    "- 클러스터의 개수를 미리 지정할 필요가 없음\n",
    "- 복잡한 형상을 찾을 수 있음\n",
    "- 어떤 클래스에도 속하지 않는 포인트를 구분할 수 있음\n",
    "- 특성 공간에서 가까이 있는 데이터가 많아 붐비는 지역의 포인트(밀집 지역)를 찾음\n",
    "- 데이터의 밀집 지역이 한 클러스터를 구성하며, 비교적 비어있는 지역을 경계로 다른 클러스터와 구분함\n",
    "- 핵심 샘플(핵심 포인트): 밀집 지역에 있는 포인트. 한 데이터 포인트에서 eps 거리 안에 데이터가 min_samples 개수만큼 들어 있으면, 핵심 샘플로 분류함\n",
    "- 무작위로 포인트를 선택한 후, 그 포인트에서 eps 거리안의 모든 포인트를 찾음. 만약 min_samples보다 적으면 그 포인트는 어떤 클래스에도 속하지 않는 잡음으로 레이블함\n",
    "- 포인트의 종류는 핵심 포인트, 경계 포인트(핵심 포인트의 eps 거리 안에 있는 포인트), 잡음 포인트가 있음\n",
    "- 새로운 데이터에 대해 예측할 수 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4ffed3-954f-4fad-8da1-5da0ada3a609",
   "metadata": {},
   "source": [
    "## **<span style=\"color:green\">군집 알고리즘의 비교와 평가</span>**\n",
    "- 군집 알고리즘이 잘 작동하는지 평가하거나, 알고리즘의 출력을 비교하기가 매우 어려움"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d0d68e-914f-4324-b96f-f932d913a3d9",
   "metadata": {},
   "source": [
    "### **타깃 값으로 군집 평가하기**\n",
    "- 1(최적일 때)과 0(무작위로 분류될 때) 사이의 값을 제공하는 ARI, NMI 지표가 있음\n",
    "- 군집 모델을 평가할 때 accuracy_score을 사용하는 것은 실수임. 포인트들이 같은 클러스터에 속해 있는가가 중요함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9274d4b8-c21f-4fb9-ae69-2a82ff72f452",
   "metadata": {},
   "source": [
    "### **타깃 값 없이 군집 평가하기**\n",
    "- 실루엣 계수가 있지만, 실제로 제대로 잘 작동하진 않음\n",
    "- 실루엣 점수는 클러스터의 밀집 정도를 계산하는 것으로, 높을수록 좋으며 최대 점수는 1임\n",
    "- 모양이 복잡할 때는 밀집도를 활용한 평가가 잘 안맞음\n",
    "- 클러스터가 우리 기대에 부합하는지 알 수 있는 방법은 클러스터를 직접 확인하는 것임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7e89a5-0961-463d-a6c6-3d00b7a66fe1",
   "metadata": {},
   "source": [
    "### **얼굴 데이터셋으로 군집 알고리즘 비교**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31230007-1257-44bb-93ac-8bb2aceb3526",
   "metadata": {},
   "source": [
    "#### **<span style=\"color:purple\">DBSCAN으로 얼굴 데이터셋 분석하기</span>** \n",
    "- 이상치 검출: 특이한 것을 찾아내는 종류의 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060996f9-3c9d-494e-b69e-9159fb38224f",
   "metadata": {},
   "source": [
    "#### **<span style=\"color:purple\">k-평균으로 얼굴 데이터셋 분석하기</span>** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54959a1f-1937-42aa-aa9b-38501057e004",
   "metadata": {},
   "source": [
    "#### **<span style=\"color:purple\">병합 군집으로 얼굴 데이터셋 분석하기</span>** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2737b6-8957-49ca-947e-99be90c70ed6",
   "metadata": {},
   "source": [
    "## **<span style=\"color:green\">군집 알고리즘의 요약</span>**\n",
    "- 군집 알고리즘을 적용하고 평가하는 것은 정성적(노가다)임\n",
    "- 탐색적 데이터 분석 단계에 크게 도움이 될 수 있음\n",
    "- 세 알고리즘에 대해 배움\n",
    "   - K-평균: 클러스터 중심을 사용해 클러스터를 구분\n",
    "   - DBSCAN: 잡음 포인트를 인식할 수 있음. 클러스터의 개수를 자동으로 결정함. 복잡한 클러스터의 모양을 인식할 수 있음. 크기가 많이 다른 클러스터를 만들어내곤 함\n",
    "   - 병합 군집: 전체 데이터의 분할 계층도를 만들어주며 덴드로그램으로 시각화할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567e3eaf-2801-4cbb-b51f-d76195be2ee0",
   "metadata": {},
   "source": [
    "# **<span style=\"color:blue\">요약 및 정리</span>** \n",
    "---\n",
    "- EDA와 데이터 전처리에 사용할 수 있는 비지도 학습 알고리즘을 배움\n",
    "- 결과를 정량화하기는 어렵지만, 데이터에 대한 통찰을 얻을 수 있음\n",
    "- 이런 핵심 알고리즘들은 모두 손에 익혀두는 것이 좋음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
