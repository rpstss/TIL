{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa9a4d11-d2b0-40e6-adb5-112402fe7848",
   "metadata": {},
   "source": [
    "## **<span style=\"color:purple\">로지스틱 회귀</span>**\n",
    "---\n",
    "- 선형 방정식을 사용한 분류 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c8097c-34d1-49c5-ad35-3ebe99921674",
   "metadata": {},
   "source": [
    "#### **k-최근접 이웃 분류기의 확률 예측**\n",
    "- 다중 분류: 타깃 데이터에 2개 이상의 클래스가 포함된 문제\n",
    "- n_neighbors의 (개수+1)만큼의 확률만 나온다는 단점이 있음. (ex) 3일 때 -> 0/3,1/3,2/3,3/3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc3d7bc-4e87-4b02-98e3-837911723399",
   "metadata": {},
   "source": [
    "#### **로지스틱 회귀** #####\n",
    "- 이름은 회귀이지만 분류 모델임\n",
    "- 선형 회귀와 동일하게 선형 방정식을 학습함\n",
    "- (ex) $z= a\\times(Weight)+b\\times(Length)+c\\times(Diagonal)+d\\times(Height)+e\\times(Width)+f$\n",
    "- 시그모이드 함수(로지스틱 함수)\n",
    "   - 확률은 0~1이기 때문에 z가 아주 큰 음수일 때 0이 되고, 큰 양수일 때 1이 되도록 바꾸기 위함\n",
    "   - $ϕ = \\frac{1}{1 + e^{-z}}$\n",
    "- 이진 분류 시 시그모이드 함수의 출력이 0.5보다 크면 양성, 0.5보다 작거나 같으면 음성 클래스로 판단함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edb887a-8738-4877-9fbd-4fb225e62d92",
   "metadata": {},
   "source": [
    "#### **로지스틱 회귀로 다중 분류 수행하기**\n",
    "- 로지스틱 회귀 클래스는 기본적으로 반복적인 알고리즘을 사용함\n",
    "- max_iter 매개변수에서 반복 횟수를 지정하며 기본값은 100임\n",
    "- 릿지 회귀와 같이 계수의 제곱을 규제함\n",
    "- 그러나 alpha 매개변수가 아니라 C 매개변수를 사용함. alpha와 다르게 C가 작을수록 규제가 큼. C의 기본값은 1임\n",
    "- 이중 분류와 달리 시그모이드 함수가 아니라, 소프트맥스 함수를 사용하여 z값을 확률로 변환함\n",
    "- 클래스마다 z값을 하나씩 계산함\n",
    "- 소프트맥스 함수\n",
    "   - $esum=e^(z1)+e^(z2)+....$\n",
    "   - $s1= e^(z1)/esum, s2=e^(z2)/esum...$\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd2d117-bcaa-4544-a1f2-df6c58b3155d",
   "metadata": {},
   "source": [
    "## **<span style=\"color:purple\">확률적 경사 하강법</span>**\n",
    "---\n",
    "- 확률적: 무작위하게 혹은 랜덤하게. 훈련 세트를 한번에 전부 사용하지 않고 랜덤하게 골라서 사용함\n",
    "- 경사 하강법: 강사를 따라 내려가는 방법. 가장 가파른 경사를 따라 원하는 지점에 도달하는 것이 목표\n",
    "- 가장 가파른 길을 찾아 내려오지만 조금씩 내려오는 것이 중요함\n",
    "- 훈련 세트에서 랜덤하게 하나의 샘플을 선택하여 가파른 경사를 조금 내려감. 이 과정을 전체 샘플을 모두 사용할 때까지 반복\n",
    "- 경사를 다 내려오지 못했다면 다시 처음부터 시작함\n",
    "- 에포크: 확률적 경사 하강법에서 훈련 세트를 한 번 모두 사용하는 과정\n",
    "- 미니배치 경사 하강법: 1개씩 말고 무작위로 몇개의 샘플을 선택해서 경사를 따라 내려가는 방식\n",
    "- 배치 경사 하강법: 한 번 경사를 따라 이동하기 위해 전체 샘플을 사용하는 방식. 가장 안정적일 수 있지만 매우 비효율적일 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20a634f-0dd6-4451-b71f-7a1ad68651ab",
   "metadata": {},
   "source": [
    "#### **점진적인 학습**\n",
    "- 훈련 데이터가 한 번에 준비되는 것이 아니라 조금씩 전달됨\n",
    "- 확률적 경사 하강법이 대표적인 점진적 학습 알고리즘임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d379da-daec-499d-be04-d9c78f04fc20",
   "metadata": {},
   "source": [
    "#### **손실 함수**\n",
    "- 어떤 문제에서 머신러닝 알고리즘이 얼마나 엉터리인지 측정하는 기준\n",
    "- 작을수록 좋지만, 어떤 값이 최솟값인지 모르기 때문에 만족할만한 수준이면 산을 다 내려왔다고 인정함\n",
    "- 경사 하강법을 사용할 때 아주 조금씩 내려와야하기 때문에 손실 함수의 값이 연속적이어야 함 -> 정확도를 사용하기 어려움. 확률을 사용함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27953dbd-f417-43f5-81f3-a9bca921c3d8",
   "metadata": {},
   "source": [
    "#### **로지스틱 손실 함수(이진 크로스엔트로피 손실 함수)**\n",
    "- 타깃이 1일 경우, 예측에 1을 곱한 값에 음수를 취함\n",
    "- 타깃이 0일 경우, (1-예측)에 1을 곱한 값에 음수를 취함\n",
    "- 위의 예측 확률에 로그함수를 적용하면 더 좋음. 양수를 얻기 위함임\n",
    "- 크로스엔트로피 손실 함수: 다중 분류에서 사용하는 손실 함수\n",
    "- 예외로, 회귀에서는 평균 제곱 오차를 많이 사용함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8038d1e-b846-4ee1-9705-6b72c127b729",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **에포크와 과대/과소 적합**\n",
    "- 일반적으로 에포크 횟수가 적으면 과소적합될 수 있음\n",
    "- 일반적으로 에포크 횟수가 많으면 과대적합될 수 있음\n",
    "- 조기 종료: 과대적합이 시작하기 전에 훈련을 멈추는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d334cf-7003-4874-9db7-ae48f9f4f9de",
   "metadata": {},
   "source": [
    "- loss 매개변수의 기본 값은 hinge(힌지 손실, 서포트 벡터 머신)임"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
