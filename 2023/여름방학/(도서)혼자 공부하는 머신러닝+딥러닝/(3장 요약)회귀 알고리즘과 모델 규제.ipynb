{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddb8483e-2749-4cff-b53c-b97287f6e2fb",
   "metadata": {},
   "source": [
    "## **<span style=\"color:purple\">k-최근접 이웃 회귀</span>**\n",
    "---\n",
    "- 지도 학습 알고리즘은 크게 분류와 회귀로 나뉨\n",
    "- 회귀: 클래스 중 하나로 분류하는 것이 아니라 임의의 어떤 숫자를 예측하는 문제, 두 변수 사이의 상관관계를 분석하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9e3c6e-9c5f-4063-828c-5da10601a556",
   "metadata": {},
   "source": [
    "#### **결정 계수(R^2)**\n",
    "- 결정계수: $ 1-(sum((타깃-예측)^2)/sum((타깃-평균)^2)$\n",
    "- 타깃의 평균 정도를 예측하는 수준이라면 결정 계수는 0에 가까워지고, 예측이 타깃에 가가워지면 결정 계수가 1에 가까워진다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2112f351-02e7-4a6b-b668-bb58d05cef02",
   "metadata": {},
   "source": [
    "#### **과대 적합 VS 과소 적합**\n",
    "- 과대 적합: 훈련 세트에서 점수가 굉장히 좋았지만, 테스트 세트에서는 점수가 굉장히 나쁜 경우\n",
    "- 과소 적합: 훈련 세트보다 테스트 세트의 점수가 높거나 두 점수가 모두 너무 낮은 경우   \n",
    "    - 모델이 너무 단순하여 훈련 세트에 적절히 훈련되지 않은 경우   \n",
    "    - 훈련 세트가 전체 데이터를 대표하지 못한 경우  \n",
    "    - 훈련 세트와 테스트 세트의 크기가 매우 작은 경우  \n",
    "    - k-최근접 이웃 알고리즘에서 k를 낮추는 방식으로 해결할 수 있음. 이는 국지적인 패턴에 민감해지도록 하기 위함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6785665-e342-4f1f-af77-3e705eb8e1eb",
   "metadata": {},
   "source": [
    "## **<span style=\"color:purple\">선형 회귀</span>**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d297f692-7ac3-4659-b007-6ceead7c4d84",
   "metadata": {},
   "source": [
    "#### **k-최근접 이웃의 한계**\n",
    "- 새로운 샘플이 훈련 세트의 범위를 벗어나면 엉뚱한 값을 예측할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83029c8c-5dfc-4bb0-834c-74cbfaeab37a",
   "metadata": {},
   "source": [
    "#### **선형 회귀**\n",
    "- 모델 기반 학습: 최적의 모델 파라미터를 찾는 것\n",
    "- 사례 기반 학습: 훈련 세트를 저장하는 것이 훈련의 전부인 것."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5911aa83-1397-4ff2-8d66-530ba34c069c",
   "metadata": {},
   "source": [
    "#### **다항 회귀**\n",
    "- 2차 방정식의 그래프를 그리려면 길이를 제곱한 항이 훈련 세트에 추가되어야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77430862-b13c-459e-b746-422bd9ff8c4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **<span style=\"color:purple\">특성 공학과 규제</span>**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a595c145-33f7-4910-b307-aa9e418fefd9",
   "metadata": {},
   "source": [
    "#### **다중 회귀**\n",
    "- 다중 회귀: 여러 개의 특성을 사용한 선형 회귀 -> 직선이 아닌 평면으로 학습\n",
    "- 특성 공학: 기존의 특성을 사용해 새로운 특성을 뽑아내는 작업\n",
    "\n",
    "#### **변환기**\n",
    "- 사이킷런은 특성을 만들거나 전처리하기 위한 클래스인 변환기를 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ac8b58-1c61-4616-b471-98291cd0fba6",
   "metadata": {},
   "source": [
    "#### **규제**\n",
    "- 규제: 머신러닝 모델이 훈련 세트를 너무 과도하게 학습하지 못하도록 훼방하는 것-> 과대적합 방지, 선형 회귀의 계수의 크기를 작게 만듬\n",
    "- 릿지: 계수를 제곱한 값을 기준으로 규제를 적용, alpha 값이 클 수록 규제 강도가 세짐 -> 계수가 더 줄어들어 선형회귀와 달라져 더 과소적합 시킴\n",
    "- 라쏘: 계수의 절댓값을 기준으로 규제를 적용, alpha 매개변수 사용, max_iter 매개변수로 반복 횟수를 설정함"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
