{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a65833ee-e383-4c5c-bf0c-ea604e655e7a",
   "metadata": {},
   "source": [
    "## **bs4**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5923111c-8dc1-4979-bf56-bbc34fd94bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "숭실대 '대학 창의적 자산 실용화 지원 사업' 선정\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "response=requests.get('https://search.naver.com/search.naver?where=news&sm=tab_jum&query=%EC%88%AD%EC%8B%A4%EB%8C%80')\n",
    "html=response.text\n",
    "\n",
    "soup=BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "word=soup.select_one(\".news_tit\")\n",
    "\n",
    "print(word.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3d8c6a1-5fea-49dd-9436-de1f7844161a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "산림청, 국민대 ‘탄소흡수원 특성화 대학원’ 지정\n",
      "https://view.asiae.co.kr/article/2023070710183880254\n",
      "------------------------\n",
      "UNIST·국민대, 초고효율 자가 치유성 열전소재 개발\n",
      "http://www.newsis.com/view/?id=NISX20230706_0002366075&cID=10814&pID=10800\n",
      "------------------------\n",
      "국민대 ‘환경’ 특화 인문사회 융합인재 양성 나선다\n",
      "http://news.heraldcorp.com/view.php?ud=20230705000198\n",
      "------------------------\n",
      "한양대 ERICA-국민대-한국로봇산업협회, 코-위크 아카데미에서 해커톤 성료\n",
      "https://biz.chosun.com/topics/topics_social/2023/07/07/UHJAXTXODRHBVOYFBWT443PA3I/?utm_source=naver&utm_medium=original&utm_campaign=biz\n",
      "------------------------\n",
      "국민대·한양대·로봇산업협, '첨단분야 인재 양성' 협약\n",
      "http://www.edaily.co.kr/news/newspath.asp?newsid=02564966635671240\n",
      "------------------------\n",
      "'이제는 때가 됐다 개식용 없는 대한민국!'..개식용 종식 촉구 국민대집회 8일...\n",
      "http://www.notepet.co.kr/news/article/article_view/?idx=28585&groupCode=AB120AD120\n",
      "------------------------\n",
      "국민대 오픈소스SW동아리 코스, 서울시 공공데이터 활용 경진대회 최우수상 수...\n",
      "https://www.etnews.com/20230707000217\n",
      "------------------------\n",
      "개식용 종식을 위한 국민행동, 8일 '2023 개식용 종식 촉구 국민대집회' 개최\n",
      "http://www.pharmnews.com/news/articleView.html?idxno=226823\n",
      "------------------------\n",
      "국민대 '고교교사 대상' 2023년 합격전략 컨퍼런스.. 천안 내달 3일 '선착순 ...\n",
      "http://www.veritas-a.com/news/articleView.html?idxno=463983\n",
      "------------------------\n",
      "aT-국민대, 저탄소 식생활·농수산식품산업 발전 MOU\n",
      "https://www.newscj.com/news/articleView.html?idxno=3042153\n",
      "------------------------\n",
      "====================================\n",
      "숭실대 '대학 창의적 자산 실용화 지원 사업' 선정\n",
      "http://www.newsis.com/view/?id=NISX20230706_0002366430&cID=10201&pID=10200\n",
      "------------------------\n",
      "LG유플러스-숭실대, '사이버 보안' 특화 전문인재 양성 본격화\n",
      "https://www.news1.kr/articles/5097059\n",
      "------------------------\n",
      "LGU+ \"숭실대 계약학과 12명 수시모집…정보보호특기자 전형도\"\n",
      "https://www.yna.co.kr/view/AKR20230704026400017?input=1195m\n",
      "------------------------\n",
      "숭실대, '대학 창의적 자산 실용화 지원' 선정…26.2억원 지원\n",
      "http://www.metroseoul.co.kr/article/20230707500015\n",
      "------------------------\n",
      "LG유플러스-숭실대, 정보보호 인재 육성 본격화\n",
      "http://www.boannews.com/media/view.asp?idx=119855&kind=\n",
      "------------------------\n",
      "신현국 문경시장, 숭실대 타당성용역 착수보고회\n",
      "http://www.ksmnews.co.kr/default/index_view_page.php?idx=434304&part_idx=340\n",
      "------------------------\n",
      "청주대, 전주대에 3-1 역전승… 홍익대·숭실대도 태백산기 첫 승\n",
      "https://isplus.com/article/view/isp202307030181\n",
      "------------------------\n",
      "숭실대학교 연극 동아리 ‘살피재 사람들’, 14~16일 ‘녹차 정원’ 창단 공연\n",
      "https://www.etnews.com/20230705000136\n",
      "------------------------\n",
      "[현장] \"퇴근길에 지하철역에서 댕댕이 간식 샀다\" 서울교통공사 반려동물용품...\n",
      "http://www.bizhankook.com/article/25932\n",
      "------------------------\n",
      "LG유플러스, 숭실대와 사이버 보안 인재 육성 나서\n",
      "https://www.lcnews.co.kr/news/articleView.html?idxno=55174\n",
      "------------------------\n",
      "====================================\n",
      "세종대, 교육부 '브릿지 3.0' 사업 선정\n",
      "http://www.newsis.com/view/?id=NISX20230707_0002367977&cID=10201&pID=10200\n",
      "------------------------\n",
      "세종대 영화예술학과 '제24회 세종 청소년 시나리오 창작대회' 개최\n",
      "http://www.veritas-a.com/news/articleView.html?idxno=464001\n",
      "------------------------\n",
      "세종대로 일대 메운 민주노총\n",
      "https://www.yna.co.kr/view/PYH20230706173600013?input=1196m\n",
      "------------------------\n",
      "[스마트AI포럼 2023 포토] 구영현 세종대 교수 발제\n",
      "https://www.newscj.com/news/articleView.html?idxno=3042859\n",
      "------------------------\n",
      "한낮 서울 도심 민주노총 7000여명 동시 집회…일대 교통 마비\n",
      "http://www.edaily.co.kr/news/newspath.asp?newsid=02955286635671896\n",
      "------------------------\n",
      "세종대, 스타트업 투자기업 와이앤아처와 업무협약\n",
      "http://www.newsis.com/view/?id=NISX20230705_0002364718&cID=10201&pID=10200\n",
      "------------------------\n",
      "세종대로 집결한 민주일반연맹\n",
      "https://www.news1.kr/photos/view/?6087951\n",
      "------------------------\n",
      "길 막히는 세종대로\n",
      "http://www.newsis.com/view/?id=NISI20230706_0019947490\n",
      "------------------------\n",
      "민주노총 5.5만명 대규모 집회 시작…세종대로·종로 \"걷는 게 빠르네\"\n",
      "https://www.news1.kr/articles/5100362\n",
      "------------------------\n",
      "민주노총, 세종대로서 전국노동자대회 [뉴시스Pic]\n",
      "http://www.newsis.com/view/?id=NISX20230706_0002367029&cID=10201&pID=10200\n",
      "------------------------\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "a = [\"국민대\",\"숭실대\",\"세종대\"]\n",
    "\n",
    "for k in a:\n",
    "    response=requests.get(f'https://search.naver.com/search.naver?where=news&sm=tab_jum&query={k}')\n",
    "    html=response.text\n",
    "\n",
    "    soup=BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    word=soup.select(\"a.news_tit\")\n",
    "    for i in word:\n",
    "        print(i.text)\n",
    "        print(i.attrs['href'])\n",
    "        print(\"------------------------\")\n",
    "        \n",
    "    print(\"====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94e9a036-8f7d-4541-8e01-85e45da5d703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 페이지 입니다.\n",
      "1번 기사 제목:[여름 구름 뉴진스①] 민희진의 진심, 담대함과 자신감\n",
      "1번 기사 링크:http://www.newsis.com/view/?id=NISX20230705_0002364185&cID=10601&pID=10600\n",
      "==========================\n",
      "2번 기사 제목:에스파 카리나, 파리 빛낸 미모\n",
      "2번 기사 링크:http://sports.khan.co.kr/news/sk_index.html?art_id=202307050956013&sec_id=540301&pt=nv\n",
      "==========================\n",
      "3번 기사 제목:에스파 윈터보다 적은 투구수…2115억 사나이, 드디어 양키스 데뷔전 나선다\n",
      "3번 기사 링크:https://www.spotvnews.co.kr/news/articleView.html?idxno=618651\n",
      "==========================\n",
      "4번 기사 제목:에스파 카리나, 명품보다 돋보이는 우아함…팬들은 ‘심쿵’\n",
      "4번 기사 링크:http://enews.imbc.com/News/RetrieveNewsInfo/387132\n",
      "==========================\n",
      "5번 기사 제목:에스파 닝닝, 어깨+골반 드러내고 치명 눈빛 “공주야?”\n",
      "5번 기사 링크:https://www.newsen.com/news_view.php?uid=202307061647290510\n",
      "==========================\n",
      "6번 기사 제목:에스파 닝닝, 입국하는 인형 [포토엔HD]\n",
      "6번 기사 링크:https://www.newsen.com/news_view.php?uid=202307051404525510\n",
      "==========================\n",
      "7번 기사 제목:[사진]에스파 카리나,'명품 가방 들고'\n",
      "7번 기사 링크:http://www.osen.co.kr/article/G1112137722\n",
      "==========================\n",
      "8번 기사 제목:엑소 카이·NCT도재정·에스파, 英NME 2023 상반기 베스트 K팝 선정\n",
      "8번 기사 링크:https://isplus.com/article/view/isp202306300029\n",
      "==========================\n",
      "9번 기사 제목:에스파 카리나 '공항 아닌 강의실 나서는 느낌의 깔끔 패션'\n",
      "9번 기사 링크:http://www.mydaily.co.kr/new_yk/html/read.php?newsid=202307050754364716&ext=na&utm_campaign=naver_news&utm_source=naver&utm_medium=related_news\n",
      "==========================\n",
      "10번 기사 제목:에스파 카리나, 매혹적인 ‘긴 생머리’ [포토엔HD]\n",
      "10번 기사 링크:https://www.newsen.com/news_view.php?uid=202307050719315510\n",
      "==========================\n",
      "###############################################################\n",
      "2 페이지 입니다.\n",
      "1번 기사 제목:에스파 윈터, 긴 머리 풀어 헤치고 몽환美 풀풀\n",
      "1번 기사 링크:http://sports.khan.co.kr/news/sk_index.html?art_id=202307051705003&sec_id=540101&pt=nv\n",
      "==========================\n",
      "2번 기사 제목:에스파 카리나, '계절 앞서간 패션' 눈부신 미모\n",
      "2번 기사 링크:https://news.jtbc.co.kr/article/article.aspx?news_id=NB12133281\n",
      "==========================\n",
      "3번 기사 제목:에스파, 인니를 품다\n",
      "3번 기사 링크:http://sports.khan.co.kr/news/sk_index.html?art_id=202306261341003&sec_id=540301&pt=nv\n",
      "==========================\n",
      "4번 기사 제목:활동 유무가 중요한 게 아냐..지수vs에스파vs르세라핌, ‘인기가요’ 1위 후보\n",
      "4번 기사 링크:http://www.osen.co.kr/article/G1112136295\n",
      "==========================\n",
      "5번 기사 제목:에스파 카리나 '비현실적 미모'[★포토]\n",
      "5번 기사 링크:https://www.starnewskorea.com/stview.php?no=2023070207430094036\n",
      "==========================\n",
      "6번 기사 제목:‘음악중심’ 르세라핌vs에스파vs(여자)아이들 걸그룹 대전\n",
      "6번 기사 링크:https://www.newsen.com/news_view.php?uid=202307011540402510\n",
      "==========================\n",
      "7번 기사 제목:에스파 카리나 vs 닝닝, 춥거나 덥거나 극과 극 공항여신[스토리엔]\n",
      "7번 기사 링크:https://www.newsen.com/news_view.php?uid=202307051721235510\n",
      "==========================\n",
      "8번 기사 제목:에스파(aespa) 닝닝, 꽃보다 아름다운 울막닝~ ‘야무진 하트까지’(입국)[뉴...\n",
      "8번 기사 링크:https://www.newsen.com/news_view.php?uid=202307051432090710\n",
      "==========================\n",
      "9번 기사 제목:에스파 닝닝, 심쿵 미모 [포토엔HD]\n",
      "9번 기사 링크:https://www.newsen.com/news_view.php?uid=202307021322015510\n",
      "==========================\n",
      "10번 기사 제목:에스파 카리나, 진정한 코트여신 [포토엔HD]\n",
      "10번 기사 링크:https://www.newsen.com/news_view.php?uid=202307020734345510\n",
      "==========================\n",
      "###############################################################\n",
      "3 페이지 입니다.\n",
      "1번 기사 제목:[MD포토] 에스파 카리나 '똘망똘망 인형 눈빛'\n",
      "1번 기사 링크:http://www.mydaily.co.kr/new_yk/html/read.php?newsid=202307020742798869&ext=na&utm_campaign=naver_news&utm_source=naver&utm_medium=related_news\n",
      "==========================\n",
      "2번 기사 제목:[MD포토] 에스파 카리나 '코트 속 각선미 공개'\n",
      "2번 기사 링크:http://www.mydaily.co.kr/new_yk/html/read.php?newsid=202307020743903026&ext=na&utm_campaign=naver_news&utm_source=naver&utm_medium=related_news\n",
      "==========================\n",
      "3번 기사 제목:[MD포토] 에스파 카리나 '미소가 미소를 부르네'\n",
      "3번 기사 링크:http://www.mydaily.co.kr/new_yk/html/read.php?newsid=202307020739653095&ext=na&utm_campaign=naver_news&utm_source=naver&utm_medium=related_news\n",
      "==========================\n",
      "4번 기사 제목:[MD포토] 에스파 카리나 '가을 여인으로 변신'\n",
      "4번 기사 링크:http://www.mydaily.co.kr/new_yk/html/read.php?newsid=202307020738503180&ext=na&utm_campaign=naver_news&utm_source=naver&utm_medium=related_news\n",
      "==========================\n",
      "5번 기사 제목:에스파(aespa) 카리나, ‘다 가려도 뷰티풀’ 마음씨도 착한 리나씨(입국)[뉴...\n",
      "5번 기사 링크:https://www.newsen.com/news_view.php?uid=202307050734510710\n",
      "==========================\n",
      "6번 기사 제목:[MD포토] 에스파 카리나 '팬들이 또 웃게 만들었어'\n",
      "6번 기사 링크:http://www.mydaily.co.kr/new_yk/html/read.php?newsid=202307020736126942&ext=na&utm_campaign=naver_news&utm_source=naver&utm_medium=related_news\n",
      "==========================\n",
      "7번 기사 제목:에스파 ‘카리나’, 공항 여행객도 감탄하는 여신 미모(출국)[뉴스엔TV]\n",
      "7번 기사 링크:https://www.newsen.com/news_view.php?uid=202307020925521310\n",
      "==========================\n",
      "8번 기사 제목:한예슬, AI 버추얼 인간 '예슬E'로 新활동..에스파 같은 행보\n",
      "8번 기사 링크:https://www.starnewskorea.com/stview.php?no=2023070408482769514\n",
      "==========================\n",
      "9번 기사 제목:\"행복하지 않다\"…'억지 논란→악플 테러' 에스파 카리나, 心 다치지 않을 권...\n",
      "9번 기사 링크:https://tenasia.hankyung.com/topic/article/2023070302164\n",
      "==========================\n",
      "10번 기사 제목:에스파 카리나 “행복하지 않아” 고백…비주얼은 완벽\n",
      "10번 기사 링크:http://enews.imbc.com/News/RetrieveNewsInfo/386794\n",
      "==========================\n",
      "###############################################################\n"
     ]
    }
   ],
   "source": [
    "# 여러 페이지 가져오기\n",
    "\n",
    "keyword = \"에스파\"\n",
    "lastpage = 3\n",
    "pageNum = 1\n",
    "\n",
    "# 마지막 페이지 번호 입력\n",
    "# 1에서 10씩 step을 주어서 반복하면 됨\n",
    "for i in range(1,lastpage*10,10):\n",
    "    \n",
    "    print(f\"{pageNum} 페이지 입니다.\")\n",
    "    response = requests.get(f\"https://search.naver.com/search.naver?where=news&sm=tab_jum&query={keyword}&start={i}\")\n",
    "    # 응답의 text를 받아오면 html 전체의 코드를 받아옴\n",
    "    html = response.text\n",
    "\n",
    "    # 원하는 정보만 가져오기 (아름다운 스푸로 가져와서 먹기좋게 바꿔야함)\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    links = soup.select(\".news_tit\")  # 결과는 리스트\n",
    "    # print(links)\n",
    "\n",
    "    a = 1\n",
    "    for link in links:\n",
    "        title = link.text          # 태그 안에 텍스트 요소를 가져온다\n",
    "        url = link.attrs['href']        # href의 속성값을 가져온다\n",
    "        print(f\"{a}번 기사 제목:{title}\")\n",
    "        print(f\"{a}번 기사 링크:{url}\")\n",
    "        print('==========================')\n",
    "        a+=1\n",
    "    print('###############################################################')    \n",
    "    pageNum = pageNum + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "508bf4ea-e84f-4b79-a3c2-740323c4954b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 페이지 입니다.\n",
      "2 페이지 입니다.\n",
      "크롤링 끝\n"
     ]
    }
   ],
   "source": [
    "# 네이버 뉴스 본문 가져오기\n",
    "keywords = \"에스파\"\n",
    "headers = { \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/98.0.4758.102\" }\n",
    "\n",
    "lastpage = 2\n",
    "pageNum = 1\n",
    "\n",
    "\n",
    "for page in range(1,lastpage*10,10):\n",
    "    print(f\"{pageNum} 페이지 입니다.\")\n",
    "    #Get 요청, naver 서버에 대화 시도\n",
    "    response = requests.get(f\"https://search.naver.com/search.naver?where=news&sm=tab_pge&query={keywords}&start={page}\")\n",
    "    #네이버에서 html 제공, text 메소드로 태그 내 텍스트만 추출\n",
    "    html = response.text\n",
    "    \n",
    "\n",
    "    #html 번역선생님으로 수프 만듦\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # 뉴스 여러개를 선택\n",
    "    news = soup.select('div.news_area')\n",
    "    for n in news:\n",
    "        title = n.select_one('a.news_tit').text\n",
    "        press = n.select_one('a.info.press').text\n",
    "        #date = n.select_one('span.info').text\n",
    "        \n",
    "        try:\n",
    "            url = n.select_one('div.info_group > a:nth-of-type(2)').attrs['href']\n",
    "            \n",
    "            \n",
    "        except: \n",
    "            continue\n",
    "        article = requests.get(url,headers=headers)\n",
    "        article_html = BeautifulSoup(article.text,\"html.parser\")\n",
    "            \n",
    "        \n",
    "        try:\n",
    "            content = article_html.select_one('#newsct_article').text\n",
    "            content = content.replace(\"\\n\", \"\")\n",
    "            \n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        print(f\"title : {title}//// press : {press} //// url : {url} //// content : {content}\")\n",
    "        \n",
    "    pageNum += 1\n",
    "    \n",
    "print(\"크롤링 끝\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bc74a22-6a6e-4fbc-bbde-e7242f1f60ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69,900\n"
     ]
    }
   ],
   "source": [
    "# 네이버 주식 크롤링하기\n",
    "# 한가지 종목 크롤링\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://finance.naver.com/item/sise.naver?code=005930\"\n",
    "response = requests.get(url)\n",
    "\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "# price = soup.select_one(\"#_nowVal\")\n",
    "price = soup.select_one(\"#_nowVal\").text\n",
    "# 숫자로 바꿔주기 위해 ','를 없애야함\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1ae2e56-5bf8-4152-9420-7fa1bd3df5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69900\n",
      "111800\n",
      "49850\n"
     ]
    }
   ],
   "source": [
    "# 여러가지 종목 크롤링\n",
    "# 가져오고 싶은 종목을 리스트로 만들어줌\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 종목 코드 리스트\n",
    "codes = ['005930','000660','035720']\n",
    "\n",
    "\n",
    "for code in codes:\n",
    "    url = f\"https://finance.naver.com/item/sise.naver?code={code}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    # price = soup.select_one(\"#_nowVal\")\n",
    "    price = soup.select_one(\"#_nowVal\").text\n",
    "    # 숫자로 바꿔주기 위해 ','를 없애야함\n",
    "    price = price.replace(',','')\n",
    "    print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa37faa1-62ad-4739-8c01-78a4e977bb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬으로 만든 크롤링 데이터 엑셀로 저장\n",
    "\n",
    "import openpyxl\n",
    "\n",
    "# 1) 엑셀 파일 만들기\n",
    "wb = openpyxl.Workbook()\n",
    "\n",
    "#2) 엑셀 워크시트 만들기\n",
    "ws = wb.create_sheet('오징어게임')\n",
    "\n",
    "# 3) 데이터 추가하기 (엑셀의 열은 A,B,C,D/ 행은 1,2,3,4)\n",
    "ws['A1'] = '참가번호'\n",
    "ws['B1'] = '성명'\n",
    "\n",
    "ws['A2'] = 1\n",
    "ws['B2'] = '오일남'\n",
    "\n",
    "# 4) 엑셀 저장하기\n",
    "# path r'C:\\folder\\folder2\\참가자_data.xlsx'\n",
    "wb.save('참가자_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40390ab4-0822-48b7-95ae-be5a0c40341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 엑셀 불러오기\n",
    "\n",
    "# fpath = r'C:\\folder\\folder2\\참가자_data.xlsx'\n",
    "wb = openpyxl.load_workbook('참가자_data.xlsx')\n",
    "\n",
    "# 엑셀 시트 선택\n",
    "ws = wb['오징어게임']\n",
    "\n",
    "# 데이터 수정하기\n",
    "ws['A3'] = 456\n",
    "ws['B3'] = '성기훈'\n",
    "\n",
    "# 엑셀 저장하기\n",
    "wb.save('참가자_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04c1e4d6-cd93-4473-8d02-ca504283c36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69900\n",
      "111800\n",
      "49850\n"
     ]
    }
   ],
   "source": [
    "#주식 크롤링 한 것을 엑셀을 불러와서 저장해보기\n",
    "\n",
    "# 엑셀 만들기\n",
    "wb = openpyxl.Workbook()\n",
    "\n",
    "# 엑셀 워크시트 만들기\n",
    "ws = wb.create_sheet('주식종목')\n",
    "\n",
    "wb.save('data.xlsx')\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import openpyxl\n",
    "\n",
    "# fpath = r'C:\\folder\\folder2\\data.xlsx'\n",
    "wb = openpyxl.load_workbook('data.xlsx')\n",
    "\n",
    "# 현재 활성화 된 시트를 선택\n",
    "# ws = wb.active\n",
    "ws = wb['주식종목']\n",
    "\n",
    "# 종목 코드 리스트\n",
    "codes = ['005930','000660','035720']\n",
    "\n",
    "\n",
    "row = 2\n",
    "for code in codes:\n",
    "    url = f\"https://finance.naver.com/item/sise.naver?code={code}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    # price = soup.select_one(\"#_nowVal\")\n",
    "    price = soup.select_one(\"#_nowVal\").text\n",
    "    # 숫자로 바꿔주기 위해 ','를 없애야함\n",
    "    price = price.replace(',','')\n",
    "    print(price)\n",
    "    ws[f'B{row}'] = int(price)\n",
    "    row = row +1\n",
    "    \n",
    "    \n",
    "wb.save('data.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a53595-b837-4b6d-af35-01c958b54f3d",
   "metadata": {},
   "source": [
    "## **Selenium**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5507400a-d183-43f8-b6ef-ed89c7e425c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 불러오기\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# CSS 선택자 입력받기 위한 패키지\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# 네이버 로그인 봇 방지\n",
    "import time\n",
    "import pyautogui  # 파이썬 마우스, 키보드 조작 라이브러리\n",
    "import pyperclip\n",
    "\n",
    "# 엔터를 누르는 패키지\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# 크롬 드라이버 자동 업데이트\n",
    "# from webdriver_manager.chrome import ChromDriverManager\n",
    "\n",
    "# 브라우저 꺼짐 방지 옵션\n",
    "chrome_options = Options()\n",
    "chrome_options.add_experimental_option(\"detach\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c08aa9cd-2f06-4d1c-a7c5-3996e9abb1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일반 버전\n",
    "service = Service(executable_path='C:/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=service,options=chrome_options)\n",
    "# 브라우저 열기\n",
    "# driver.get('https://www.naver.com/')\n",
    "\n",
    "# 네이버 로그인 주소로\n",
    "driver.implicitly_wait(5) # 웹페이지가 로딩 될때까지 5초는 기다림\n",
    "driver.maximize_window()  # 화면 최대화\n",
    "driver.get('https://nid.naver.com/nidlogin.login?mode=form&url=https://www.naver.com/')\n",
    "\n",
    "# 아이디 입력창\n",
    "id = driver.find_element(By.CSS_SELECTOR, \"#id\")\n",
    "id.click()\n",
    "id.send_keys(\"ss\")\n",
    "\n",
    "# 비밀번호 입력창\n",
    "pw = driver.find_element(By.CSS_SELECTOR, \"#pw\")\n",
    "pw.click()\n",
    "pw.send_keys(\"gn3!\")\n",
    "\n",
    "# 로그인 버튼\n",
    "login_btn = driver.find_element(By.CSS_SELECTOR, \"#log\\.login\")\n",
    "login_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dbcdbd0-bc73-4dc0-ba5d-c7617ee583c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 봇 제거 버전\n",
    "\n",
    "service = Service(executable_path='C:/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=service,options=chrome_options)\n",
    "# 브라우저 열기\n",
    "# driver.get('https://www.naver.com/')\n",
    "\n",
    "# 네이버 로그인 주소로\n",
    "driver.implicitly_wait(5) # 웹페이지가 로딩 될때까지 5초는 기다림\n",
    "driver.maximize_window()  # 화면 최대화\n",
    "driver.get('https://nid.naver.com/nidlogin.login?mode=form&url=https://www.naver.com/')\n",
    "\n",
    "# 아이디 입력창\n",
    "id = driver.find_element(By.CSS_SELECTOR, \"#id\")\n",
    "id.click()                    # send_key를 작성하는 부분에서 오류가 발생\n",
    "pyperclip.copy(\"m\")       # 다른 기능은 한글을 사용하지 못하기 때문에 사용 (사람이 한 것처럼 만들기 위해서)\n",
    "pyautogui.hotkey(\"ctrl\",\"v\") # 맥은 커맨드, 키보드라고 생각하면 됨\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "# 비밀번호 입력창\n",
    "pw = driver.find_element(By.CSS_SELECTOR, \"#pw\")\n",
    "pw.click()\n",
    "pyperclip.copy(\"gnsl1!\")\n",
    "pyautogui.hotkey(\"ctrl\",\"v\") # 맥은 커맨드\n",
    "time.sleep(2)\n",
    "\n",
    "# 로그인 버튼\n",
    "login_btn = driver.find_element(By.CSS_SELECTOR, \"#log\\.login\")\n",
    "login_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32b42ab2-8697-4592-a5e7-1fba2ae8e2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple 정품 아이폰 14 Pro 자급제 딥퍼플 1TB MQ323KH/A\n",
      "Apple 정품 아이폰 14 Pro 자급제 스페이스블랙 128GB MPXV3KH/A\n",
      "Apple 정품 아이폰 14 자급제 퍼플 256GB MPWA3KH/A\n",
      "Apple 정품 아이폰 14 Pro Max 자급제 스페이스블랙 128GB MQ9P3KH/A\n",
      "Apple 정품 아이폰 14 Pro 자급제 실버 256GB MQ103KH/A\n",
      "Apple 정품 아이폰 14 자급제 스타라이트 256GB MPW43KH/A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# 상품 정보 div\\nitems = driver.find_elements(By.CSS_SELECTOR,\".adProduct_info_area__dTSZf\")\\n\\n\\nfor item in items:\\n    name = item.find_element(By.CSS_SELECTOR,\".product_link__TrAac.linkAnchor\").text\\n    try:\\n        price = item.find_element(By.CSS_SELECTOR,\"span.price_num__S2p_v\").text\\n\\n    except:\\n        price = \"판매중단\"\\n    print(name,price)\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service = Service(executable_path='C:/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=service,options=chrome_options)\n",
    "\n",
    "# 네이버 브라우저 가져오기\n",
    "driver.implicitly_wait(5) # 웹페이지가 로딩 될때까지 5초는 기다림\n",
    "driver.maximize_window()  # 화면 최대화\n",
    "driver.get('https://www.naver.com/')\n",
    "\n",
    "# 브라우저 메뉴 클릭\n",
    "driver.find_element(By.CSS_SELECTOR,'#shortcutArea > ul > li:nth-child(4) > a').click()\n",
    "\n",
    "time.sleep(2)\n",
    "driver.close()\n",
    "driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "# 검색창을 찾을 때까지 기다려주는 명령어\n",
    "time.sleep(2)\n",
    "\n",
    "# 검색창 클릭\n",
    "search = driver.find_element(By.CSS_SELECTOR,'input._searchInput_search_text_3CUDs')\n",
    "search.click()\n",
    "\n",
    "# 검색어 입력\n",
    "search.send_keys('아이폰 14')\n",
    "search.send_keys(Keys.ENTER) # 엔터 명령어\n",
    "\n",
    "\n",
    "\n",
    "# 스크롤 전 높이\n",
    "# 현재 스코롤된 높이를 알 수 있는 자바스크립트 명령어 이용 - window.scrollY\n",
    "before_h = driver.execute_script(\"return window.scrollY\")  # 자바스크립트 명령어를 사용하게 해줌 (현재 스크롤 된 높이를 return)\n",
    "\n",
    "# 무한 스크롤 (반복문 사용 - 무한 반복문 while)\n",
    "while True:\n",
    "    # 맨 아래로 스크롤을 내린다.\n",
    "    # 웹사이트는 body tag가 웬만하면 있음\n",
    "    driver.find_element(By.CSS_SELECTOR,\"body\").send_keys(Keys.END)  # END키임 스크롤을 아래로 내림\n",
    "\n",
    "    # 스크롤 사이 페이지 로딩 시간 (과부하가 걸리지 않게 하기 위해)\n",
    "    time.sleep(1)\n",
    "\n",
    "    # 스크롤 후 높이\n",
    "    after_h = driver.execute_script(\"return window.scrollY\")\n",
    "\n",
    "    # 스크롤 했을 때 전 높이와 후 높이가 같으면 더 이상 내려가지 못함\n",
    "    if after_h == before_h:\n",
    "        break\n",
    "\n",
    "    before_h = after_h\n",
    "\n",
    "items = driver.find_elements(By.CSS_SELECTOR,\".adProduct_link__NYTV9.linkAnchor\")\n",
    "\n",
    "for item in items:\n",
    "    print(item.text)\n",
    "\n",
    "'''\n",
    "# 상품 정보 div\n",
    "items = driver.find_elements(By.CSS_SELECTOR,\".adProduct_info_area__dTSZf\")\n",
    "\n",
    "\n",
    "for item in items:\n",
    "    name = item.find_element(By.CSS_SELECTOR,\".product_link__TrAac.linkAnchor\").text\n",
    "    try:\n",
    "        price = item.find_element(By.CSS_SELECTOR,\"span.price_num__S2p_v\").text\n",
    "\n",
    "    except:\n",
    "        price = \"판매중단\"\n",
    "    print(name,price)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
